{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7acf064d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from PIL import Image\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import pickle as pkl\n",
    "import random"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "55fb65de",
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "import torch\n",
    "from matplotlib import pyplot as plt\n",
    "from pykeops.torch import LazyTensor\n",
    "import numpy as np\n",
    "use_cuda = torch.cuda.is_available()\n",
    "dtype = torch.float32 if use_cuda else torch.float64\n",
    "device_id = \"cuda:0\" if use_cuda else \"cpu\"\n",
    "# from utils import get_sample_params_from_subdiv, get_sample_locations\n",
    "import numpy as np\n",
    "from utils_rad import get_sample_params_from_subdiv, get_sample_locations, distort_image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "331aa44c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torchvision.transforms import transforms\n",
    "t2pil = transforms.ToTensor()\n",
    "pil = transforms.ToPILImage()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "52c13e91",
   "metadata": {},
   "source": [
    "# K-means clustring function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4de171cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "def KMeans(x, c, K=10, Niter=10, verbose=True):\n",
    "    \"\"\"Implements Lloyd's algorithm for the Euclidean metric.\"\"\"\n",
    "\n",
    "    B, N, D = x.shape  # Number of samples, dimension of the ambient space\n",
    "\n",
    "    x_i = LazyTensor(x.view(B, N, 1, D))  # (N, 1, D) samples\n",
    "    c_j = LazyTensor(c.view(B, 1, K, D))  # (1, K, D) centroids\n",
    "\n",
    "    D_ij = ((x_i - c_j) ** 2).sum(B, -1)  # (N, K) symbolic squared distances\n",
    "    cl = D_ij.argmin(dim=2).long().view(B, -1)  # Points -> Nearest cluster\n",
    "\n",
    "    return cl, c"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8d98c701",
   "metadata": {},
   "source": [
    "# Calibration pickel "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6f019ec9",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('/home-local2/akath.extra.nobkp/woodscapes/calib.pkl', 'rb') as f:\n",
    "    data = pkl.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5fd5b263",
   "metadata": {},
   "outputs": [],
   "source": [
    "key = list(data.keys())\n",
    "len(key)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "13af0075",
   "metadata": {},
   "outputs": [],
   "source": [
    "grid = torch.empty([len(key), 4096, 100, 2])\n",
    "grid.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9356163c",
   "metadata": {},
   "source": [
    "# Sample points"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "92c32d14",
   "metadata": {},
   "outputs": [],
   "source": [
    "# sampling_loc = []\n",
    "# # D = torch.tensor([339.749, -31.988, 48.275, -7.201]).reshape(1,4).transpose(1,0).cuda()\n",
    "# D = torch.tensor([0, 0, 0, 0]).reshape(1,4).transpose(1,0).cuda(\"cuda:1\")\n",
    "# # a = torch.tensor([0.0, 0.375, 3.047911227757854]).reshape(1, 3).transpose(0,1).cuda(\"cuda:1\") ### (16, 16)\n",
    "# a = torch.tensor([0.0, 1.5, 3.047911227757854]).reshape(1, 3).transpose(0,1).cuda(\"cuda:1\")\n",
    "# # a = torch.tensor([1.0, 33.535136959282696, 3.047911227757854]).reshape(1, 3).transpose(0,1).cuda()\n",
    "dic = {}\n",
    "for i in range(len(key)):\n",
    "    D = torch.tensor(data[key[i]].reshape(1,4).transpose(1,0)).cuda(\"cuda:0\")\n",
    "    \n",
    "    azimuth_subdiv = 128\n",
    "    radius_subdiv = 32\n",
    "    subdiv = (radius_subdiv, azimuth_subdiv)\n",
    "    # subdiv = 3\n",
    "    n_radius = 10\n",
    "    n_azimuth = 10\n",
    "    img_size = (64, 64)\n",
    "    radius_buffer, azimuth_buffer = 200, 200\n",
    "    params, D_s = get_sample_params_from_subdiv(\n",
    "        subdiv=subdiv,\n",
    "        img_size=img_size,\n",
    "        D = D, \n",
    "        n_radius=n_radius,\n",
    "        n_azimuth=n_azimuth,\n",
    "        radius_buffer=radius_buffer,\n",
    "        azimuth_buffer=azimuth_buffer, \n",
    "        distortion_model = 'polynomial')\n",
    "\n",
    "    sample_locations = get_sample_locations(**params)  ## B, azimuth_cuts*radius_cuts, n_radius*n_azimut\n",
    "    B, n_p, n_s = sample_locations[0].shape\n",
    "    x_ = sample_locations[0].reshape(1, n_p, n_s, 1).float()\n",
    "    x_ = x_/ 64\n",
    "    y_ = sample_locations[1].reshape(1, n_p, n_s, 1).float()\n",
    "    y_ = y_/64\n",
    "#     out = torch.cat((y_, x_), dim = 3)\n",
    "    grid_ = torch.cat((x_, y_), dim=3)\n",
    "    grid[i] = grid_[0]\n",
    "    print(i)\n",
    "#     import pdb;pdb.set_trace()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "48b7ae57",
   "metadata": {},
   "outputs": [],
   "source": [
    "grid[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d3501245",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('/home-local2/akath.extra.nobkp/woodscapes/grid_sample.pkl', 'wb') as f:\n",
    "    pkl.dump(dic, f)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "decbe6c2",
   "metadata": {},
   "source": [
    "# Defining image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f8846b9a",
   "metadata": {},
   "outputs": [],
   "source": [
    "im1 = Image.open('/home-local2/akath.extra.nobkp/woodscapes/rgb_images/00164_FV.png')\n",
    "im2 = Image.open('/home-local2/akath.extra.nobkp/woodscapes/rgb_images/00164_FV.png')\n",
    "im1 = im1.resize((64, 64))\n",
    "im2 = im2.resize((64, 64))\n",
    "arr1 = t2pil(im1).reshape(1, 3, 64, 64)\n",
    "arr2 = t2pil(im2).reshape(1, 3, 64, 64)\n",
    "# im1 = pil(arr)\n",
    "arr = torch.cat((arr1, arr2), dim=0).cuda(\"cuda:1\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d23c58aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "B, n_p, n_s = sample_locations[0].shape\n",
    "x_ = sample_locations[0].reshape(B, n_p, n_s, 1).float()\n",
    "x_ = x_/ 32\n",
    "y_ = sample_locations[1].reshape(B, n_p, n_s, 1).float()\n",
    "y_ = y_/32\n",
    "out = torch.cat((y_, x_), dim = 3)\n",
    "out = out.cuda(\"cuda:1\")\n",
    "out.shape\n",
    "grid_ = torch.repeat_interleave(out, 2, 0).cuda(\"cuda:1\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "40c1d8f8",
   "metadata": {},
   "source": [
    "# Sample vs feature matrix and definig grid for sampling points "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7896a244",
   "metadata": {},
   "outputs": [],
   "source": [
    "tensor = nn.functional.grid_sample(arr, grid_, align_corners = True)\n",
    "out_ = tensor.view(2, 3, -1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8daa3beb",
   "metadata": {},
   "outputs": [],
   "source": [
    "x = sample_locations[0].reshape(1, 1, -1).transpose(1,2)\n",
    "x = torch.repeat_interleave(x, 2, 0).cuda(\"cuda:1\")\n",
    "y = sample_locations[1].reshape(1, 1, -1).transpose(1,2)\n",
    "y = torch.repeat_interleave(y, 2, 0).cuda(\"cuda:1\")\n",
    "grid = torch.cat((x, y), 2)\n",
    "grid.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b37a0371",
   "metadata": {},
   "source": [
    "# Grid for pixel points"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7dde0e52",
   "metadata": {},
   "outputs": [],
   "source": [
    "x = torch.linspace(0, 128, 129) - 64.5\n",
    "y = torch.linspace(0, 128, 129) - 64.5\n",
    "grid_x, grid_y = torch.meshgrid(x[1:], y[1:], indexing='ij')\n",
    "x_ = grid_x.reshape(128*128, 1)\n",
    "y_ = grid_y.reshape(128*128, 1)\n",
    "grid_pix = torch.cat((x_, y_), dim=1)\n",
    "grid_pix = grid_pix.reshape(1, 128*128, 2)\n",
    "grid_pix = torch.repeat_interleave(grid_pix, grid.shape[0], 0)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f82cb325",
   "metadata": {},
   "outputs": [],
   "source": [
    "grid = grid.reshape(8234, -1, 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d4245fc5",
   "metadata": {},
   "outputs": [],
   "source": [
    "grid.shape, grid_pix.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cd00ff03",
   "metadata": {},
   "outputs": [],
   "source": [
    "def resample(grid, grid_pix, H, B):\n",
    "    B, N, D, K = grid.shape[0], grid.shape[1], 2, grid_pix.shape[1]\n",
    "    cl, c = KMeans(grid/(H//2), grid_pix/(H//2), K)\n",
    "#     import pdb;pdb.set_trace()\n",
    "    ind = torch.arange(N).reshape(1, -1)\n",
    "    ind = torch.repeat_interleave(ind, B, 0)\n",
    "    mat = torch.zeros(B, K, N)\n",
    "    mat[:, cl, ind] = 1\n",
    "#     output = output.reshape(B, L, -1).transpose(1, 2)\n",
    "#     pixel_out = torch.matmul(mat, output)\n",
    "#     div = mat.sum(-1).unsqueeze(2)\n",
    "#     div[div == 0] = 1\n",
    "#     pixel_out = torch.div(pixel_out, div)\n",
    "#     pixel_out = pixel_out.transpose(2, 1).reshape(B, 3, H, H)\n",
    "    return mat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a40668bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "key"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "91332359",
   "metadata": {},
   "outputs": [],
   "source": [
    "B, N, D = grid.shape\n",
    "B, N_p, D = grid_pix.shape\n",
    "dic = {}\n",
    "for i in range(grid.shape[0]):\n",
    "    g = grid[i].reshape(1, N, D)\n",
    "    g_p = grid_pix[i].reshape(1, N_p, D)\n",
    "    x = resample(g, g_p, 128, 2)\n",
    "    import pdb;pdb.set_trace()\n",
    "#     dic[key[i]] = x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bafdfc25",
   "metadata": {},
   "outputs": [],
   "source": [
    "grid_pix.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2f131dd6",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "94aa7784",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "swin",
   "language": "python",
   "name": "swin"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
